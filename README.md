# Capstone RAG System

## Overview
This project is a capstone implementation of a Retrieval-Augmented Generation (RAG) system.
The system is being developed incrementally, starting with a local language model and conversational memory.

## Current Status
**Sprint 1:** Local LLM + LangChain conversational memory  
- Running a local LLM via Ollama
- Wrapped with LangChain
- Supports multi-turn conversations with memory

## Tech Stack
- Python 3.9+
- LangChain
- Ollama (local LLM)

## Next Steps
- Document loading and preprocessing
- Embeddings and vector storage
- Full RAG pipeline


## How to run
-Make sure python 3.11.9 is installed: Python 3.11.9 - April 2, 2024
https://www.python.org/downloads/windows/ 
  -This is the most stable version LangChain and used in production RAG systems today
  
