# Capstone RAG System

## Overview
This project is a capstone implementation of a Retrieval-Augmented Generation (RAG) system.
The system is being developed incrementally, starting with a local language model and conversational memory.

## Current Status
**Sprint 1:** Local LLM + LangChain conversational memory  
- Running a local LLM via Ollama
- Wrapped with LangChain
- Supports multi-turn conversations with memory

## Tech Stack
- Python 3.9+
- LangChain
- Ollama (local LLM)

## Next Steps
- Document loading and preprocessing
- Embeddings and vector storage
- Full RAG pipeline
